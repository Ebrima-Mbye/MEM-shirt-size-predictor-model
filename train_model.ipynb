{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de1bf9",
   "metadata": {},
   "source": [
    "# MEM Shirt Size Model — Training Notebook\n",
    "\n",
    "This notebook trains a **shirt size prediction model** that outputs one of:\n",
    "\n",
    "- `S`\n",
    "- `M`\n",
    "- `L`\n",
    "- `XL`\n",
    "- `XXL`\n",
    "\n",
    "The dataset used here is **synthetic** (generated) so you can iterate quickly without collecting data first.\n",
    "\n",
    "For production accuracy, we should later replace the synthetic generator with real measurements / size-chart labels from your actual merch vendor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde1ed0",
   "metadata": {},
   "source": [
    "## 1) Notebook Runtime & Reproducibility Setup (seeds, device, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "MODEL_PATH = REPO_ROOT / \"app\" / \"model.joblib\"\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Model output path:\", MODEL_PATH)\n",
    "\n",
    "# Note: scikit-learn wheels may not exist yet for very new Python versions.\n",
    "# If imports fail later, run this notebook using a Python 3.11 kernel OR use Docker.\n",
    "# Docker approach (from repo root):\n",
    "#   docker build -t mem-shirt-size:local .\n",
    "#   docker run --rm -v \"$(pwd -W)\":/code -w /code mem-shirt-size:local python train_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bfedc5",
   "metadata": {},
   "source": [
    "## 2) Install/Verify Dependencies (VS Code + Jupyter kernel)\n",
    "\n",
    "This prints versions so the run is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09536659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"joblib:\", joblib.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903f3ae",
   "metadata": {},
   "source": [
    "## 3) Load Data (generated) + Basic Validation\n",
    "\n",
    "We generate a synthetic dataset using `train_model.generate_synthetic_dataset()`.\n",
    "\n",
    "Features:\n",
    "- `height_cm`\n",
    "- `weight_kg`\n",
    "- `age`\n",
    "- `gender`\n",
    "- `fit_preference`\n",
    "- `build`\n",
    "\n",
    "Label:\n",
    "- `size` in `{S, M, L, XL, XXL}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979db4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from train_model import SIZES, generate_synthetic_dataset\n",
    "\n",
    "rows, y = generate_synthetic_dataset(n=30_000, seed=SEED)\n",
    "\n",
    "print(\"Samples:\", len(rows))\n",
    "print(\"Labels:\", SIZES)\n",
    "print(\"Label distribution:\")\n",
    "print(Counter(y))\n",
    "\n",
    "print(\"Example row:\")\n",
    "print(rows[0], \"=>\", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a43a6",
   "metadata": {},
   "source": [
    "## 4) Train/Validation/Test Split\n",
    "\n",
    "We do a stratified split inside `train_model.train_model()` for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab5c58",
   "metadata": {},
   "source": [
    "## 5) Preprocessing Pipeline (scaling/encoding)\n",
    "\n",
    "We use a scikit-learn `Pipeline` with:\n",
    "- numeric scaling (`StandardScaler`)\n",
    "- categorical one-hot encoding (`OneHotEncoder`)\n",
    "\n",
    "This is already implemented in `train_model.train_model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080f7f7",
   "metadata": {},
   "source": [
    "## 6) Dataset/DataLoader Construction\n",
    "\n",
    "This project uses scikit-learn (not PyTorch), so we don’t need a DataLoader.\n",
    "\n",
    "Our “dataset” is a list of Python dicts (`rows`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8faba4",
   "metadata": {},
   "source": [
    "## 7) Define Model Architecture\n",
    "\n",
    "We use a **multinomial Logistic Regression** baseline (fast + interpretable) via scikit-learn.\n",
    "\n",
    "If you want later, we can switch to Gradient Boosting (often better) once we have real labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccbf83",
   "metadata": {},
   "source": [
    "## 8) Define Loss, Metrics, Optimizer, Scheduler\n",
    "\n",
    "For scikit-learn Logistic Regression:\n",
    "- loss/optimizer are internal\n",
    "- metrics are computed after training (accuracy + per-class precision/recall/F1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269f3eb",
   "metadata": {},
   "source": [
    "## 9) Training Loop (epochs, batching, checkpointing)\n",
    "\n",
    "We train in one call to scikit-learn’s `.fit()` and save artifacts as a single `joblib` file in `app/model.joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fda63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from train_model import ModelArtifact, train_model\n",
    "\n",
    "pipeline, metrics = train_model(rows, y, seed=SEED)\n",
    "print(\"Holdout accuracy:\", metrics[\"accuracy\"])\n",
    "\n",
    "artifact = ModelArtifact(\n",
    "    version=\"shirt-size-v1\",\n",
    "    trained_at=datetime.now(timezone.utc).isoformat(),\n",
    "    labels=[\"S\", \"M\", \"L\", \"XL\", \"XXL\"],\n",
    "    feature_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"height_cm\", \"weight_kg\", \"age\", \"gender\", \"fit_preference\", \"build\"],\n",
    "        \"properties\": {\n",
    "            \"height_cm\": {\"type\": \"number\", \"minimum\": 120, \"maximum\": 230},\n",
    "            \"weight_kg\": {\"type\": \"number\", \"minimum\": 30, \"maximum\": 250},\n",
    "            \"age\": {\"type\": \"integer\", \"minimum\": 10, \"maximum\": 100},\n",
    "            \"gender\": {\"type\": \"string\", \"enum\": [\"female\", \"male\", \"other\"]},\n",
    "            \"fit_preference\": {\"type\": \"string\", \"enum\": [\"slim\", \"regular\", \"oversized\"]},\n",
    "            \"build\": {\"type\": \"string\", \"enum\": [\"lean\", \"average\", \"athletic\", \"curvy\"]},\n",
    "        },\n",
    "    },\n",
    "    pipeline=pipeline,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(asdict(artifact), MODEL_PATH)\n",
    "print(\"Saved:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f91d7b",
   "metadata": {},
   "source": [
    "## 10) Evaluation Loop (metrics + confusion matrix/plots)\n",
    "\n",
    "We’ll compute a confusion matrix on a quick re-split for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx = np.arange(len(rows))\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_train = [rows[i] for i in train_idx]\n",
    "X_test = [rows[i] for i in test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, labels=list(SIZES), normalize=\"true\", cmap=\"Blues\")\n",
    "disp.ax_.set_title(\"Normalized confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10b577",
   "metadata": {},
   "source": [
    "## 11) Hyperparameter Tuning (small grid/random search)\n",
    "\n",
    "A tiny grid search over Logistic Regression strength. This is intentionally small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "C_grid = [0.2, 0.5, 1.0, 2.0]\n",
    "results = []\n",
    "\n",
    "idx = np.arange(len(rows))\n",
    "train_idx, val_idx = train_test_split(idx, test_size=0.2, random_state=SEED, stratify=y)\n",
    "X_train = [rows[i] for i in train_idx]\n",
    "X_val = [rows[i] for i in val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "for C in C_grid:\n",
    "    model = clone(pipeline)\n",
    "    model.set_params(clf__C=C)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    results.append({\"C\": C, \"val_accuracy\": float(accuracy_score(y_val, pred))})\n",
    "\n",
    "results_sorted = sorted(results, key=lambda r: r[\"val_accuracy\"], reverse=True)\n",
    "print(\"Top configs:\")\n",
    "for r in results_sorted:\n",
    "    print(r)\n",
    "\n",
    "best_C = results_sorted[0][\"C\"]\n",
    "print(\"Best C:\", best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85a202",
   "metadata": {},
   "source": [
    "## 12) Save/Load Artifacts (model + preprocessors)\n",
    "\n",
    "The API expects a single `joblib` file at `app/model.joblib` containing:\n",
    "- preprocessing + classifier pipeline\n",
    "- labels\n",
    "- schema\n",
    "- metadata (version, trained_at)\n",
    "\n",
    "We can also reload it here to confirm everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62853cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load(MODEL_PATH)\n",
    "print(\"Loaded keys:\", loaded.keys())\n",
    "print(\"Loaded version:\", loaded.get(\"version\"))\n",
    "print(\"Loaded labels:\", loaded.get(\"labels\"))\n",
    "\n",
    "loaded_pipeline = loaded[\"pipeline\"]\n",
    "print(\"Pipeline steps:\", loaded_pipeline.named_steps.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee322c87",
   "metadata": {},
   "source": [
    "## 13) Inference on New Samples (single + batch)\n",
    "\n",
    "This mirrors what the FastAPI `/predict` endpoint does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"height_cm\": 176,\n",
    "    \"weight_kg\": 78,\n",
    "    \"age\": 24,\n",
    "    \"gender\": \"male\",\n",
    "    \"fit_preference\": \"regular\",\n",
    "    \"build\": \"average\",\n",
    "}\n",
    "\n",
    "proba = loaded_pipeline.predict_proba([sample])[0]\n",
    "labels = loaded_pipeline.classes_\n",
    "\n",
    "probs = {str(lbl): float(p) for lbl, p in zip(labels, proba)}\n",
    "recommended = max(probs.items(), key=lambda kv: kv[1])[0]\n",
    "\n",
    "print(\"Recommended:\", recommended)\n",
    "print(\"Probabilities:\")\n",
    "for k, v in sorted(probs.items(), key=lambda kv: kv[1], reverse=True):\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "batch = [\n",
    "    sample,\n",
    "    {\"height_cm\": 162, \"weight_kg\": 55, \"age\": 19, \"gender\": \"female\", \"fit_preference\": \"slim\", \"build\": \"lean\"},\n",
    "    {\"height_cm\": 182, \"weight_kg\": 105, \"age\": 33, \"gender\": \"male\", \"fit_preference\": \"regular\", \"build\": \"curvy\"},\n",
    "]\n",
    "print(\"Batch predictions:\", list(loaded_pipeline.predict(batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c92874",
   "metadata": {},
   "source": [
    "## 14) Export Core Code to `.py` Module for Reuse\n",
    "\n",
    "This repo already does that:\n",
    "- training logic is in [train_model.py](MEM-shirt-size-predictor-model/train_model.py)\n",
    "- picklable transformers are in [app/feature_utils.py](MEM-shirt-size-predictor-model/app/feature_utils.py)\n",
    "\n",
    "The notebook imports and calls those functions so you don’t end up with two divergent implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59f6d7",
   "metadata": {},
   "source": [
    "## 15) Add Unit Tests (smoke tests for data + model)\n",
    "\n",
    "Below is a minimal `pytest` test file content you can copy into `tests/test_model_smoke.py` if you want automated checks.\n",
    "\n",
    "(We’re not creating the file automatically here unless you ask.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r\"\"\"\n",
    "# tests/test_model_smoke.py\n",
    "\n",
    "import joblib\n",
    "\n",
    "from train_model import generate_synthetic_dataset, train_model\n",
    "\n",
    "\n",
    "def test_training_runs():\n",
    "    rows, y = generate_synthetic_dataset(n=2000, seed=123)\n",
    "    pipeline, metrics = train_model(rows, y, seed=123)\n",
    "    assert metrics[\"accuracy\"] > 0.5\n",
    "    assert hasattr(pipeline, \"predict\")\n",
    "\n",
    "\n",
    "def test_artifact_loads(tmp_path):\n",
    "    rows, y = generate_synthetic_dataset(n=2000, seed=123)\n",
    "    pipeline, _ = train_model(rows, y, seed=123)\n",
    "    out = tmp_path / \"model.joblib\"\n",
    "    joblib.dump({\"pipeline\": pipeline, \"labels\": [\"S\", \"M\", \"L\", \"XL\", \"XXL\"]}, out)\n",
    "    loaded = joblib.load(out)\n",
    "    assert \"pipeline\" in loaded\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d518e3",
   "metadata": {},
   "source": [
    "## 16) VS Code Execution Cells + Output Pane Logging (structured logs)\n",
    "\n",
    "Quick pattern: use Python’s `logging` module so output is consistent across cells and scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"mem-shirt-size\")\n",
    "\n",
    "logger.info(\"Notebook ready. Model path: %s\", MODEL_PATH)\n",
    "logger.info(\"Tip: run sections top-to-bottom.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
